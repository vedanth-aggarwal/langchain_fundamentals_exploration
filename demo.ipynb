{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "048fa328-b118-44cc-9abf-f4682510eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3089c5-f6bb-4ff4-9274-f610a1dd18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bd2fc7-1ee8-4f29-9bf3-e72ced611d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(openai.models.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c927d0ba-6f14-487d-9293-ed9ac2dcb3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
       "      <td>(created, 1685474247)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, gpt-4)</td>\n",
       "      <td>(created, 1687882411)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, gpt-4-1106-preview)</td>\n",
       "      <td>(created, 1698957206)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, gpt-4-0613)</td>\n",
       "      <td>(created, 1686588896)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
       "      <td>(created, 1686587434)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
       "      <td>(created, 1677649963)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(id, gpt-4-1106-vision-preview)</td>\n",
       "      <td>(created, 1711473033)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(id, gpt-4-vision-preview)</td>\n",
       "      <td>(created, 1698894917)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(id, gpt-4-turbo-2024-04-09)</td>\n",
       "      <td>(created, 1712601677)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(id, gpt-4-turbo-preview)</td>\n",
       "      <td>(created, 1706037777)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(id, gpt-4-0125-preview)</td>\n",
       "      <td>(created, 1706037612)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(id, gpt-4-turbo)</td>\n",
       "      <td>(created, 1712361441)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0                      1                2  \\\n",
       "0        (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
       "1                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
       "2                   (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
       "3             (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
       "4                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
       "5                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
       "6                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
       "7                         (id, gpt-4)  (created, 1687882411)  (object, model)   \n",
       "8                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
       "9            (id, gpt-4-1106-preview)  (created, 1698957206)  (object, model)   \n",
       "10                   (id, gpt-4-0613)  (created, 1686588896)  (object, model)   \n",
       "11  (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
       "12       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
       "13                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
       "14           (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
       "15           (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
       "16                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
       "17                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
       "18       (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
       "19                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
       "20           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
       "21    (id, gpt-4-1106-vision-preview)  (created, 1711473033)  (object, model)   \n",
       "22       (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
       "23         (id, gpt-4-vision-preview)  (created, 1698894917)  (object, model)   \n",
       "24       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
       "25       (id, gpt-4-turbo-2024-04-09)  (created, 1712601677)  (object, model)   \n",
       "26           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
       "27          (id, gpt-4-turbo-preview)  (created, 1706037777)  (object, model)   \n",
       "28           (id, gpt-4-0125-preview)  (created, 1706037612)  (object, model)   \n",
       "29                  (id, gpt-4-turbo)  (created, 1712361441)  (object, model)   \n",
       "\n",
       "                              3  \n",
       "0            (owned_by, openai)  \n",
       "1   (owned_by, openai-internal)  \n",
       "2            (owned_by, system)  \n",
       "3   (owned_by, openai-internal)  \n",
       "4            (owned_by, system)  \n",
       "5            (owned_by, system)  \n",
       "6            (owned_by, system)  \n",
       "7            (owned_by, openai)  \n",
       "8            (owned_by, system)  \n",
       "9            (owned_by, system)  \n",
       "10           (owned_by, openai)  \n",
       "11           (owned_by, system)  \n",
       "12           (owned_by, system)  \n",
       "13  (owned_by, openai-internal)  \n",
       "14           (owned_by, openai)  \n",
       "15           (owned_by, openai)  \n",
       "16           (owned_by, system)  \n",
       "17           (owned_by, system)  \n",
       "18           (owned_by, system)  \n",
       "19           (owned_by, openai)  \n",
       "20           (owned_by, system)  \n",
       "21           (owned_by, system)  \n",
       "22           (owned_by, system)  \n",
       "23           (owned_by, system)  \n",
       "24  (owned_by, openai-internal)  \n",
       "25           (owned_by, system)  \n",
       "26           (owned_by, system)  \n",
       "27           (owned_by, system)  \n",
       "28           (owned_by, system)  \n",
       "29           (owned_by, system)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(openai.models.list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de358101-b1e2-4202-8a24-b3c9e7256674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"I am an AI digital assistant and I don't have a physical form or name. You can just call me Assistant. How can I assist you today?\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-proj-5PtJfS13Mw2cwvIBscB6T3BlbkFJAbonhz5auCPZwxjzp6NL\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What's your name!\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,n=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e1c03d9-4853-4b3f-bc13-345cfc4bf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"Hi am vedanth a student at IIT delhi with 97/100 percentage and am a member of debate club\"\n",
    "\n",
    "# Zero shot promt is a direct question\n",
    "# Few shot prompt is multiple subcategories\n",
    "\n",
    "prompt=f'''\n",
    "Please extract following information from given text and return json object: \n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract info from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69fa52d3-f527-4f92-a105-eecc085456b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'$.messages[0].content' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-5PtJfS13Mw2cwvIBscB6T3BlbkFJAbonhz5auCPZwxjzp6NL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#temperature=1,\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#max_tokens=256,\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#top_p=1,\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#frequency_penalty=0,\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#presence_penalty=0,n=1\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:581\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    580\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1232\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1220\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1229\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1230\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1012\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1011\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1016\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1020\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'$.messages[0].content' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-proj-5PtJfS13Mw2cwvIBscB6T3BlbkFJAbonhz5auCPZwxjzp6NL\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "  ],\n",
    "  #temperature=1,\n",
    "  #max_tokens=256,\n",
    "  #top_p=1,\n",
    "  #frequency_penalty=0,\n",
    "  #presence_penalty=0,n=1\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfb30c4-77e5-41b1-88b5-2c317267f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'vedanth',\n",
       " 'college': 'IIT delhi',\n",
       " 'grades': '97/100 percentage',\n",
       " 'club': 'debate club'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d0352b-cdb1-4287-91a1-72c55418e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2527217-6e1c-4f34-8c2c-3d0efdfabdfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'name' is a required property - 'functions.0'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response2 \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent_custom_function\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response2)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:581\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    580\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1232\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1220\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1229\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1230\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1012\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1011\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1016\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1020\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'name' is a required property - 'functions.0'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt }],\n",
    "    functions=student_custom_function\n",
    ")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78865d7f-4ac2-4c23-9b9d-3e141ef7cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response2.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26465318-7be4-43c5-88b8-7cd5f8e54394",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_functions = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'major': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Major subject.'\n",
    "                },\n",
    "                'school': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The university name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'GPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'School club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810544fa-0f31-4934-a2e5-ccff234ce9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_descriptions = [student_description]\n",
    "for i in student_description:\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': i}],\n",
    "        functions = student_custom_functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    # Loading the response as a JSON object\n",
    "    json_response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5398cb85-6ef1-4770-bb11-171f1e711d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 48 countries in Asia, so it is not possible to have a top 10. However, here are the top 10 countries in Asia based on population (as of 2021):\\n\\n1. China\\n2. India\\n3. Indonesia\\n4. Pakistan\\n5. Bangladesh\\n6. Japan\\n7. Philippines\\n8. Vietnam\\n9. Iran\\n10. Thailand'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_openai import OpenAI\n",
    "client=OpenAI(openai_api_key=\"sk-proj-5PtJfS13Mw2cwvIBscB6T3BlbkFJAbonhz5auCPZwxjzp6NL\")\n",
    "prompt='Number of top 10 countries in asia and can you name them?'\n",
    "client.invoke(prompt).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9130018f-1fa1-414f-8cea-9bf257d3a390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLimitations of OpenAI API\\n- Not a free model \\n- Can access any LLM using langchain \\n- GPT only till september 2021\\n- Can access private data sources\\n- Can access any 3rd party API\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HUGGING FACE API, LANGCHAIN \n",
    "# OpenAI usage\n",
    "# Prompt templating\n",
    "# Chains\n",
    "# Agent \n",
    "# SERP API - GOOGLE SEARCH API\n",
    "# Memory \n",
    "# Document loader \n",
    "\n",
    "\"\"\"\n",
    "Limitations of OpenAI API\n",
    "- Not a free model \n",
    "- Can access any LLM using langchain \n",
    "- GPT only till september 2021\n",
    "- Can access private data sources\n",
    "- Can access any 3rd party API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f1e1391-34e9-4a94-ad40-e845dfb12ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "394b9f4a-8477-48f6-ac91-33831861c264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me the capital of Delhi?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = PromptTemplate(\n",
    "    input_variables=['city'],\n",
    "    template='Can you tell me the capital of {city}?'\n",
    "    )\n",
    "\n",
    "pt.format(city='Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87df1c87-8bc6-4c35-9439-0cb2fd9ed00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most recent Cricket World Cup was won by England in 2019.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent\n",
    "prompt4 = 'Who won recent cricket world cup'\n",
    "client.invoke(prompt4).strip() # only 2021 or before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a574c78c-f951-4b28-bb70-71760f7b8a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "# For extracting real time info use serp API\n",
    "# Call google search engine and extract info in real time\n",
    "\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3c7b3ea-cd67-4ad1-821b-d5180fb40c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_key = \"b486fb1f15a30a20522b826c974977d990addada4a708d6d51d651bcd14b8cae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd7976e2-7e19-4b88-9d04-faeb22dc0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType,load_tools,initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a54f70a-fcef-4dc7-a235-f0d34e489fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"sk-proj-5PtJfS13Mw2cwvIBscB6T3BlbkFJAbonhz5auCPZwxjzp6NL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d46424-9698-42d8-9ca2-614cf1957feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "tool = load_tools(['serpapi'],serpapi_api_key=serpapi_key,llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "812616df-2738-4867-a643-1a9ac3ff3c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92aa9e06-3aee-48d0-bedb-889d13627bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Hmm, I'm not sure who won the world cup in cricket recently.\n",
      "Action: Search\n",
      "Action Input: \"recent world cup in cricket winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'title': 'ICC Cricket World Cup', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb79cf344c0bb1324154b32d129fc98cc305f046caf18a157eef.png', 'games': [{'tournament': 'ICC Cricket World Cup', 'stadium': 'Narendra Modi Stadium', 'date': 'Nov 19, 23', 'teams': [{'name': 'India', 'score': '240 (50)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cddd623bcb85cbf4cd5f8365ae8002ebc6bc28f7533ac0d9d78651f09f59a5b3bf.png'}, {'name': 'Australia', 'score': '241/4 (43)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cddd623bcb85cbf4cdfde62daa6a05c086328ce2f3840b8249a49dadf7fef0eff5.png'}], 'status': 'AUS won by 6 wickets (42 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 16, 23', 'teams': [{'name': 'South Africa', 'score': '212 (49.4)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd717ab04145174c91c83c72eb1da2a4f8793cba603bd3e259b7b0bd75e0f882b4.png'}, {'name': 'Australia', 'score': '215/7 (47.2)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd717ab04145174c91e1e1a19a3c4922de8de16039b6c77efea40b7aaade24bcdf.png'}], 'status': 'AUS won by 3 wickets (16 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Wankhede Stadium', 'date': 'Nov 15, 23', 'teams': [{'name': 'India', 'score': '397/4 (50)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd875c9b9931eaf4ef010a817403dec0c48c8327316a0e645aa1ad47c831658cc9.png'}, {'name': 'New Zealand', 'score': '327 (48.5)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd875c9b9931eaf4ef9fb196c48cb69c16e03480503d3cb8dede22f8b669668feb.png'}], 'status': 'IND won by 70 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'M. Chinnaswamy Stadium', 'date': 'Nov 12, 23', 'teams': [{'name': 'India', 'score': '410/4 (50)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd0eb9cfb65d8d00c0093906752dbcd76a98014eff8f99f9ca86d995757d9b9f0b.png'}, {'name': 'Netherlands', 'score': '250 (47.5)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd0eb9cfb65d8d00c08cfe56f09d15969740137baf45c8d05f50d9171598b96201.png'}], 'status': 'IND won by 160 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 11, 23', 'teams': [{'name': 'England', 'score': '337/9 (50)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd20e3e909d910ec505481ec371e94228a36d4af4cb1ac459c131e0803e942619f.png'}, {'name': 'Pakistan', 'score': '244 (43.3)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd20e3e909d910ec50676d4c4f3d920c9d9eb9ef6b790153a462a1cf367c954430.png'}], 'status': 'ENG won by 93 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Maharashtra Cricket Association Stadium', 'date': 'Nov 11, 23', 'teams': [{'name': 'Bangladesh', 'score': '306/8 (50)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd44836f9a5ebf028144d1fe825adda2227e68caadb6f81adce8dd096cb6864bef.png'}, {'name': 'Australia', 'score': '307/2 (44.4)', 'thumbnail': 'https://serpapi.com/searches/66251a05f8f5f706a4b4d430/images/b494c28aed56bb798e3159a52efa98cd44836f9a5ebf0281afe996299173cacf495d33adba88f3e701a024e7ae1c03a6.png'}], 'status': 'AUS won by 8 wickets (32 balls left)'}]}\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: ` It looks like Australia won the recent world cup in cricket.\nAction: None`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1166\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:731\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    730\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:76\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[0;32m     75\u001b[0m ):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n\u001b[0;32m     79\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     80\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     81\u001b[0m     )\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: ` It looks like Australia won the recent world cup in cricket.\nAction: None`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWho won recent world cup in cricket?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1432\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1432\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1441\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1442\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1148\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1148\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1177\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m-> 1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1182\u001b[0m     )\n\u001b[0;32m   1183\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: ` It looks like Australia won the recent world cup in cricket.\nAction: None`"
     ]
    }
   ],
   "source": [
    "agent.invoke('Who won recent world cup in cricket?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e60a05fa-2e05-4fa4-ada1-6e975e5c37b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1e2dd4a-3c08-471d-baed-d4a391e276e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should first think about what to do\n",
      "Action: wikipedia\n",
      "Action Input: Cricket World Cup\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Cricket World Cup\n",
      "Summary: The Cricket World Cup (officially known as ICC Men's Cricket World Cup) is the international championship of One Day International (ODI) cricket. The event is organised by the sport's governing body, the International Cricket Council (ICC), every four years, with preliminary qualification rounds leading up to a finals tournament. The tournament is one of the world's most viewed sporting events and considered as the \"flagship event of the international cricket calendar\" by the ICC. It is widely considered the pinnacle championship of the sport of cricket.\n",
      "The first World Cup was organised in England in June 1975, with the first ODI cricket match having been played only four years earlier. However, a separate Women's Cricket World Cup had been held two years before the first men's tournament, and a tournament involving multiple international teams had been held as early as 1912, when a triangular tournament of Test matches was played between Australia, England and South Africa. The first three World Cups were held in England. From the 1987 tournament onwards, hosting has been shared between countries under an unofficial rotation system, with fourteen ICC members having hosted at least one match in the tournament.\n",
      "The current format involves a qualification phase, which takes place over the preceding three years, to determine which teams qualify for the tournament phase. In the tournament phase, 10 teams, including the automatically qualifying host nation, compete for the title at venues within the host nation over about a month. In the 2027 edition, the format will be changed to accommodate an expanded 14-team final competition.\n",
      "A total of twenty teams have competed in the 13 editions of the tournament, with ten teams competing in the recent 2023 tournament. Australia has won the tournament six times, India and West Indies twice each, while Pakistan, Sri Lanka and England have won it once each. The best performance by a non-full-member team came when Kenya made the semi-finals of the 2003 tournament.\n",
      "Australia are the current champions after winning the 2023 World Cup in India. The subsequent 2027 World Cup will be held jointly in South Africa, Zimbabwe and Namibia.\n",
      "\n",
      "Page: 2023 Cricket World Cup\n",
      "Summary: The 2023 ICC Men's Cricket World Cup (also referred to as simply the 2023 Cricket World Cup) was the 13th edition of the Cricket World Cup, a quadrennial One Day International (ODI) cricket tournament organized by the International Cricket Council (ICC). It was hosted from 5 October to 19 November 2023 across ten venues in India.\n",
      "The tournament was contested by ten national teams, maintaining the same format used in 2019. In the knockout stage, India and Australia beat New Zealand and South Africa respectively to advance to the final, played on 19 November at Narendra Modi Stadium. Australia won by 6 wickets, winning their sixth Cricket World Cup title.\n",
      "Virat Kohli was the player of the tournament and also scored the most runs; Mohammed Shami was the leading wicket-taker. A total of 1,250,307 spectators attended matches, the highest number in any Cricket World Cup to-date. The tournament final set viewership records in India, with 518 million viewers, and a peak of 57 million streaming viewers.\n",
      "\n",
      "\n",
      "\n",
      "Page: 2011 Cricket World Cup\n",
      "Summary: The 2011 ICC Cricket World Cup was the tenth Cricket World Cup. It was played in India, Sri Lanka, and for the first time in Bangladesh. India won the tournament, defeating Sri Lanka by 6 wickets in the final at Wankhede Stadium in Mumbai, thus becoming the first country to win the Cricket World Cup final on home soil. India's Yuvraj Singh was declared as the player of the tournament. This was the first time in World Cup history that two Asian teams had appeared in the final. It was also the first time since the 1992 World Cup that the final match did not feature Australia.\n",
      "Fourteen national cricket teams took part in this tournament, including 10 full members and f\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should now have enough information to answer the question\n",
      "Final Answer: The 2011 Cricket World Cup was won by India. \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cricket world cup recent winner',\n",
       " 'output': 'The 2011 Cricket World Cup was won by India.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool = load_tools(['wikipedia'],llm=client)\n",
    "agent = initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True,handle_parsing_errors=True)\n",
    "agent.invoke('Cricket world cup recent winner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e3e95-1acc-4cad-92ab-cad2b4f16f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAINS \n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template('What is name for company that makes {product}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418a2b51-a921-4462-8e95-a3677a94b2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Wine', 'text': '\\n\\nA winery or vineyard.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=client,prompt=prompt)\n",
    "chain.invoke('Wine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923f2aee-bbb5-4440-98eb-ffcfed3af576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template='I want to open a restaurant for {cuisine} food, suggest a fancy name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65bcdb28-5700-4c9d-9025-517065ada70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'chinese', 'text': '\\n\\n\"Imperial Dragon Dining\"'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=client,prompt=prompt_template)\n",
    "chain.invoke('chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f14dc7d-63c8-4a3a-bf30-53cb3897a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple chain and set a sequence - Simple sequential chain\n",
    "\n",
    "# Example 2\n",
    "prompt_template1 = PromptTemplate(\n",
    "    input_variables=['startup_name'],\n",
    "    template='I want to open a startup for {cuisine} food, suggest a fancy name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf49967-3733-49f6-aa78-9b46d62fe946",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = LLMChain(llm=client,prompt=prompt_template1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49912954-9057-419f-ab59-a1528c8da85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = PromptTemplate(\n",
    "    input_variables=['name'],\n",
    "    template='Can you tell me some strategies for {name}?'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68eb66f5-3174-44e7-aea6-f9c2f4d2748f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt_template2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chain2 \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mclient,prompt\u001b[38;5;241m=\u001b[39m\u001b[43mprompt_template2\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prompt_template2' is not defined"
     ]
    }
   ],
   "source": [
    "chain2 = LLMChain(llm=client,prompt=prompt_template2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd8b46af-f3f7-47a4-a2d4-88b7cfac8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e7b380-b3ce-46b6-b97e-b9cd5fe30456",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chain\u001b[38;5;241m=\u001b[39mSimpleSequentialChain(chains\u001b[38;5;241m=\u001b[39m[chain1,\u001b[43mchain2\u001b[49m]) \u001b[38;5;66;03m# only give end answer\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chain2' is not defined"
     ]
    }
   ],
   "source": [
    "chain=SimpleSequentialChain(chains=[chain1,chain2]) # only give end answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ee9ca41-7bc5-420f-8c15-92f627f25b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'artificial intelligence',\n",
       " 'output': '\\n\\n1. Incorporate AI into the menu planning: Use AI algorithms to analyze customer preferences, dietary restrictions, and food trends to create a menu that appeals to a wide range of tastes and dietary needs.\\n\\n2. Offer personalized recommendations: Use AI-powered recommendation engines to suggest dishes to customers based on their past orders, feedback, and food preferences.\\n\\n3. Use AI for ingredient sourcing: Partner with local farms and suppliers that use AI and machine learning to grow and source ingredients. This will not only ensure fresh and high-quality ingredients but also add a unique element to the dining experience.\\n\\n4. Integrate AI into the cooking process: Use smart kitchen appliances and AI-powered cooking tools to enhance the cooking process and create dishes that are perfectly cooked and consistent every time.\\n\\n5. Use virtual assistants: Incorporate virtual assistants, such as chatbots, to interact with customers and provide them with information about the dishes, ingredients, and cooking techniques used.\\n\\n6. Offer AI-guided wine pairings: Use AI to recommend the perfect wine pairing for each dish, based on flavor profiles and customer preferences.\\n\\n7. Create an interactive dining experience: Use augmented reality or virtual reality to enhance the dining experience. For example, customers can use their smartphones to scan a dish and learn more about the ingredients'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('artificial intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be9d0b60-fc63-414c-838c-cb736429dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential chain\n",
    "# Example 2\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template='I want to open a restaurant for {cuisine} food, suggest a fancy name')\n",
    "\n",
    "name_chain = LLMChain(llm=client,prompt=prompt_template_name,output_key='restaurant_name')\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template='Give me menu items for {restaurant_name}')\n",
    "\n",
    "item_chain =  LLMChain(llm=client,prompt=prompt_template_items,output_key='menu_items')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e05f8ce-1131-45b2-939c-cf15085bd1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'indian',\n",
       " 'restaurant_name': '\\n\\n\"Spice Symphony\" ',\n",
       " 'menu_items': '\\n\\n1. Chicken Tikka Masala\\n2. Lamb Vindaloo\\n3. Vegetable Biryani\\n4. Tandoori Shrimp\\n5. Saag Paneer\\n6. Samosas\\n7. Garlic Naan\\n8. Chana Masala\\n9. Butter Chicken\\n10. Aloo Gobi\\n11. Mango Lassi\\n12. Palak Kofta\\n13. Chicken Korma\\n14. Fish Curry\\n15. Dal Makhani\\n16. Mixed Vegetable Pakoras\\n17. Gulab Jamun\\n18. Chicken Biryani\\n19. Malai Kofta\\n20. Tandoori Chicken.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[name_chain,item_chain],\n",
    "                        input_variables=['cuisine'],\n",
    "                        output_variables=['restaurant_name','menu_items'])\n",
    "\n",
    "chain.invoke('indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee918cce-ebb0-4584-ba94-6309bde2b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\vedan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Document loaders\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afee0a81-fd21-4711-82fe-0615add02359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\vedan\\OneDrive\\Desktop\\VedanthAggarwal_ChatbotProject\\Artificial Intelligence.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0bc72ff0-5d17-4948-804b-f48c1f0ab19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Artificial Intelligence: Transforming the Present and Shaping the Future : \\nIn the realm of technological advancement, few concepts have captured the human imagination as \\nvividly as artificial intelligence (AI). With its origins tracing back to the mid -20th century, AI has \\nevolved from a speculative concept into a groundbreaking r eality that permeates every facet of \\ncontemporary life. This essay explores the evolution, impact, and potential of artificial intelligence, \\nhighlighting its transformative power in shaping society, economy, and culture.  \\nThe Evolution of Artificial Intelli gence: From Dreams to Reality : \\nThe birth of AI can be attributed to the works of visionaries like Alan Turing, who laid the foundation \\nfor modern computing and posed the question of whether machines can exhibit intelligent behavior. \\nThe ensuing decades saw the development of early AI systems that could perform simple tasks and \\nsolve mathematical problems. However, true breakthroughs occurred with the advent of neural \\nnetworks and machine learning, which mimicked the human brain's ability to learn and adapt.  \\nIn recent years, AI's evolution has been accelerated by the exponential growth in computing power \\nand the availability of massive datasets. Deep learning, a subset of machine learning, has propelled \\nAI to astonishing heights, enabling it to excel in tasks such as image recognition, language translation, \\nand even complex games like Go. With the integration of AI into various fields, from healthcare to \\nfinance, its impact on society has become increasingly profound.  \\nThe Impact of AI: Revolutionizing Industrie s and Enhancing Human Life : \\nThe transformative power of AI is most evident in its influence on industries. In healthcare, AI \\nalgorithms are diagnosing diseases with remarkable accuracy, aiding doctors in making informed \\ndecisions. The automotive sector is w itnessing the development of self -driving cars, promising \\nenhanced safety and efficiency on roads. In finance, AI -powered algorithms are revolutionizing \\ntrading and risk assessment. These examples underscore AI's potential to streamline processes, \\nreduce e rrors, and create entirely new possibilities.  \\nAdditionally, AI is shaping the entertainment landscape, from creating realistic computer -generated \\nimagery in movies to personalizing recommendations on streaming platforms. Virtual assistants like \\nSiri and Al exa have become fixtures in homes, revolutionizing the way we interact with technology. \\nLanguage models, like the one generating this essay, demonstrate AI's prowess in generating human -\\nlike text and aiding in content creation.  \\nEthical and Social Considera tions: Navigating the Path Forward : \\nAs AI continues to evolve, it brings forth a multitude of ethical and social considerations. Privacy \\nconcerns arise from the extensive data collection required to train AI models, raising questions about \\nhow data is used and protected. The potential for job displacement due to automation prompts \\ndiscussions on upskilling the workforce and ensuring equitable access to opportunities. Bias in AI \\nalgorithms, often reflecting the biases present in training data, highlights the need for fair and \\naccountable AI systems.  \\nThe ethical dimensions of AI extend to questions about its potential to develop consciousness or \\nexhibit behaviors that might challenge human control. The concept of superintelligent AI, capable of \\noutperforming hu man intellect, has led to debates about the control and regulation of such systems \\nto prevent unintended consequences.  \\nThe Road Ahead: Navigating the Promises and Challenges :\", metadata={'source': 'C:\\\\Users\\\\vedan\\\\OneDrive\\\\Desktop\\\\VedanthAggarwal_ChatbotProject\\\\Artificial Intelligence.pdf', 'page': 0}),\n",
       " Document(page_content=\"The future of artificial intelligence is both promising and challenging. On one ha nd, AI holds the \\npotential to revolutionize industries, enhance human life, and solve complex global problems such as \\nclimate change and healthcare disparities. On the other hand, the rapid pace of AI development \\nnecessitates careful consideration of its i mplications.  \\nTo navigate these challenges, collaboration between governments, academia, industry, and society at \\nlarge is crucial. Robust regulations, ethical guidelines, and transparent practices are essential to \\nensure AI's responsible and equitable depl oyment. Investments in education and training will \\nempower individuals to harness the power of AI and adapt to the changing landscape.  \\nConclusion : \\nArtificial intelligence has transcended its origins as a speculative concept to become an integral part \\nof mod ern society. Its transformative impact on industries, coupled with ethical and societal \\nconsiderations, paints a complex picture of its potential. As we move forward, embracing AI's \\nbenefits while addressing its challenges will be pivotal in shaping a futu re where artificial intelligence \\ncoexists harmoniously with human ingenuity. The journey ahead demands vigilance, collaboration, \\nand a commitment to the responsible advancement of technology for the betterment of humanity.  \\nAI Models:  \\nGPT-3 (Generative Pre -trained Transformer 3):  Developed by OpenAI, GPT -3 is one of the largest \\nlanguage models to date, capable of generating human -like text and performing a variety of natural \\nlanguage processing tasks.  \\nBERT (Bidirectional Encoder Representation s from Transformers):  Another creation by Google AI, \\nBERT revolutionized natural language understanding by training on both directions of text context, \\nenabling it to better comprehend the nuances of language.  \\nImageNet:  While not a single model, the ImageN et Large Scale Visual Recognition Challenge marked \\na pivotal moment in computer vision. The challenge led to the development of deep convolutional \\nneural networks that achieved unprecedented accuracy in image classification tasks.  \\nAI Companies:  \\nOpenAI:  Known for developing state -of-the-art language models like GPT -3, OpenAI is a research \\norganization focused on advancing artificial intelligence while ensuring its responsible deployment.  \\nGoogle AI:  A division of Google, Google AI is at the forefro nt of AI research and innovation. They've \\ndeveloped numerous AI models, including BERT, and continue to pioneer advancements in various AI \\nfields.  \\nDeepMind:  Acquired by Google in 2014, DeepMind is known for creating AI systems that have \\nachieved breakthrou ghs in games like Go and StarCraft II, as well as contributing to medical research \\nand healthcare applications.  \\nNVIDIA:  A leading company in graphics processing units (GPUs), NVIDIA plays a critical role in \\nproviding the hardware necessary for training dee p neural networks efficiently.  \\nRecent Innovations:  \\nAlphaFold:  Developed by DeepMind, AlphaFold is an AI system that accurately predicts protein \\nstructures, a problem that had stumped scientists for decades. This innovation has profound \\nimplications for dru g discovery and bioengineering.\", metadata={'source': 'C:\\\\Users\\\\vedan\\\\OneDrive\\\\Desktop\\\\VedanthAggarwal_ChatbotProject\\\\Artificial Intelligence.pdf', 'page': 1}),\n",
       " Document(page_content=\"OpenAI's DALL -E and CLIP:  Building upon GPT -3, DALL -E can generate images from textual \\ndescriptions, while CLIP can understand and relate images and text, enabling a wide range of creative \\napplications.  \\nFacebook's BlenderBot : Facebook AI's BlenderBot is designed to carry out more dynamic and \\nengaging conversations with users, showcasing advancements in natural language understanding and \\ninteraction.  \\nTesla's Full Self -Driving (FSD) Beta:  While still under development, Tesla's FSD Beta represents a \\nsignificant advancement in autonomous driving technology, using neural networks to process real -\\nworld driving data and make decisions in complex environments.  \\nThese examples underscore the rapid pace of innovation in the AI field, wit h models, companies, and \\nbreakthroughs continually pushing the boundaries of what artificial intelligence can achieve. As the \\nAI landscape evolves, these entities and innovations serve as beacons guiding us into an increasingly \\nintelligent and interconnect ed future.\", metadata={'source': 'C:\\\\Users\\\\vedan\\\\OneDrive\\\\Desktop\\\\VedanthAggarwal_ChatbotProject\\\\Artificial Intelligence.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d748e6ab-43ce-413a-8611-3f8fd14279d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMORY\n",
    "import langchain\n",
    "from langchain_openai import OpenAI\n",
    "client=OpenAI(openai_api_key=\"sk-proj-5PtJfS13Mw2cwvIBscB6T3BlbkFJAbonhz5auCPZwxjzp6NL\")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "079eaaa0-74cb-4dcf-b612-3779d52ec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template = 'What is good name for company that makes {product}')\n",
    "\n",
    "#from langchain.chains import SequentialChain\n",
    "chain = LLMChain(llm=client,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae87cb7f-a44f-4ecc-a170-8ae7cfd6a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template = 'What is good name for company that makes {product}')\n",
    "\n",
    "chain = LLMChain(llm=client,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e799dab4-949e-4b57-8df4-571edd1116b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2c4f3c4-d578-4701-a35d-0e1f4b5feb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template = 'What is good name for company that makes {product}')\n",
    "\n",
    "chain = LLMChain(llm=client,prompt=prompt_template,memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8efac855-1f74-4a05-bbc4-19fc877f5396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'toys', 'history': '', 'text': '\\n\\n\"Playful Creations\" '}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('toys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19cb9fef-59ac-427d-bbac-9e7a96139bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'camera',\n",
       " 'history': 'Human: toys\\nAI: \\n\\n\"Playful Creations\" ',\n",
       " 'text': '\\n\\n\"CaptureTech\" or \"LensCraft\" or \"FocusWorks\" or \"ShutterTech\" or \"PixelPro\" or \"VisionWorks\" or \"ClickCraft\" or \"FrameMakers\" or \"SnapTech\"'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1dbfe56-9925-43a4-9925-441489238cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: toys\n",
      "AI: \n",
      "\n",
      "\"Playful Creations\" \n",
      "Human: camera\n",
      "AI: \n",
      "\n",
      "\"CaptureTech\" or \"LensCraft\" or \"FocusWorks\" or \"ShutterTech\" or \"PixelPro\" or \"VisionWorks\" or \"ClickCraft\" or \"FrameMakers\" or \"SnapTech\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8922dada-2097-46af-947d-3d02b5cfba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationChain\n",
    "# Buffer memory goes growing endlessly, but I just want last 5 or last 20 convo\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "convo = ConversationChain(llm=OpenAI(openai_api_key=OPENAI_API_KEY,temperature=0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b402a071-774b-4b90-afc7-ef46389994d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cab1531-5683-4c0a-ab47-86896e39e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The first cricket world cup was held in 1975 and was won by the West Indies. They defeated Australia in the final by 17 runs. The West Indies' captain Clive Lloyd was named the player of the tournament.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('Who won 1st cricket world cup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf497f34-0101-4bf6-95c1-b352f5cf1ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+5 equals 10. This is a basic mathematical equation that is widely known and used. It is part of the fundamental principles of mathematics and is often used in everyday life, such as when calculating a bill or determining the number of items in a group.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('5+5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b92ed54b-c6a4-401a-a4f4-b094ecb356b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  5*5 equals 25. This is another basic mathematical equation that represents multiplication. It is often used in situations where we need to find the total of repeated groups, such as counting the number of fingers on two hands or calculating the area of a square.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('5*5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6cc7e5e8-2ef9-4edf-a40c-5ab3eb4d80b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As mentioned earlier, the captain of the winning team was Clive Lloyd. He was a legendary cricketer from the West Indies who led his team to victory in the first cricket world cup. He was known for his strong leadership skills and exceptional batting abilities.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('who was the captain of the winning team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc8c52ea-5c0e-4f97-bf5b-d806c3f9b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "memory1 = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26b65030-5b6a-4109-a959-a0ef31157a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = ConversationChain(llm=OpenAI(openai_api_key=OPENAI_API_KEY,temperature=0.7),memory=memory1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca533434-4a42-40e9-b600-e0d45a7aff38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was won by the West Indies in 1975. They beat Australia in the final by 17 runs. The West Indies team consisted of players such as Clive Lloyd, Viv Richards, and Michael Holding. The tournament was held in England and was only 60 overs per side.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('who won 1st cricket world cup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9f8adba-eb38-4ccb-b414-25829bc4b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+5 is equal to 10. In mathematics, this is known as a simple addition equation. It follows the basic rule that when two numbers are added together, the sum is equal to the total of both numbers combined.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('5+5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7be82b36-09bc-42e4-ac87-b842267e43d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I do not have enough information to answer that question. Do you have a specific team or sport in mind?'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run('who was captain of winning team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f13e1-835e-49d9-92ec-c727f822ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
